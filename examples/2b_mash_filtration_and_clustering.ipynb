{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2b Mash filtration & clustering\n",
    "\n",
    "In this notebook, we run Mash to generate genome-wise pairwise similarity scores (which correspond to Average Nucleotide Identify (ANI) & DNA-DNA reassociation value).\n",
    "\n",
    "Mash will be used as a final filtration metric to filter out strains which are too dissimilar from the rest of the genome collection."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import subprocess\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.cluster.hierarchy as hc\n",
    "import scipy.spatial as sp\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from kneebow.rotor import Rotor\n",
    "\n",
    "# pyphyon import\n",
    "import pyphylon.mash as mash\n",
    "from pyphylon.util import load_config"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "CONFIG = load_config(\"config.yml\")\nWORKDIR = CONFIG[\"WORKDIR\"]\noutput_folder = os.path.join(\"../output/\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "RAW = os.path.join(WORKDIR, \"1b_protected/raw\")\n",
    "RAW_GENOMES = os.path.join(RAW, \"genomes\")\n",
    "FNA_GENOMES = os.path.join(RAW, \"genomes/fna\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scrubbed_species_summary = pd.read_csv(os.path.join(output_folder, '2a_genome_summary.csv'), index_col=0, dtype={'genome_id': str})\n",
    "scrubbed_species_metadata = pd.read_csv(os.path.join(output_folder, '2a_genome_metadata.csv'), index_col=0, dtype={'genome_id': str})\n",
    "\n",
    "\n",
    "display(\n",
    "    scrubbed_species_summary.shape,\n",
    "    scrubbed_species_summary.head(),\n",
    "    scrubbed_species_metadata.shape,\n",
    "    scrubbed_species_metadata.head()\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Mash\n",
    "\n",
    "- Use Snakemake to run MASH.  See example/readme.md\n",
    "\n",
    "WSL workaround\n",
    "\n",
    "```bash\n",
    "  MSYS_NO_PATHCONV=1 wsl -d pangenome bash -c \"\n",
    "    source ~/miniforge3/etc/profile.d/conda.sh && \\\n",
    "    conda activate pangenome && \\\n",
    "    cd /mnt/f/lab_projects/pangenomics/pyphylon && \\\n",
    "    mkdir -p temp/2b_mash && \\\n",
    "    mash sketch -o temp/2b_mash/combined_sketch temp/1b_protected/raw/genomes/fna/*.fna && \\\n",
    "    mash dist temp/2b_mash/combined_sketch.msh temp/2b_mash/combined_sketch.msh > temp/2b_mash/mash_distances.txt\n",
    "  \"\n",
    "```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Mash filtration and clustering"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "names = [\n    'genome1',\n    'genome2',\n    'mash_distance',\n    'p_value',\n    'matching_hashes'\n]\n\nTEMP_DIR = CONFIG.get(\"REUSE_TEMP_DIR\", \"../temp/\")\ndf_mash = pd.read_csv(os.path.join(TEMP_DIR, '2b_mash/mash_distances.txt'), sep='\\t', names=names)\ndf_mash['genome1'] = df_mash['genome1'].apply(lambda x: x.split('/')[-1].split('.fna')[0])\ndf_mash['genome2'] = df_mash['genome2'].apply(lambda x: x.split('/')[-1].split('.fna')[0])\n\ndf_mash",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_mash_square = df_mash.pivot(index='genome1', columns='genome2', values='mash_distance')\n",
    "\n",
    "display(\n",
    "    df_mash_square.shape,\n",
    "    df_mash_square.head()\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "sns.heatmap(df_mash_square, cmap='viridis')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate corressponding pearson-correlation matrix (& distance matrix)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# This may take HOURS to run\n# Once finished it will IMMEDIATELY save all 3 matrices\n# so you don't have to re-compute this over and over again\n\ndf_mash_corr = df_mash_square.corr()\ndf_mash_corr_dist = 1 - df_mash_corr\ndf_mash_corr_dist\n\n# Save matrix so the next time, only the following cell needs to be run\n# This cell should be commented out after being run once\ndf_mash_corr_dist.to_csv(os.path.join(output_folder, '2b_mash_corr_dist.csv'))\n\ndisplay(\n    df_mash_corr_dist.shape,\n    df_mash_corr_dist.head()\n)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter by scrubbed genomes\n",
    "\n",
    "Based on any cleaning that may have been done in `2a`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TEMP filter scrubbed strains to onle include those in the mash matrix\n",
    "scrubbed_strains = scrubbed_species_metadata.genome_id.astype('str')\n",
    "scrubbed_strains = scrubbed_strains[scrubbed_strains.isin(df_mash_corr_dist.index.astype(str))]\n",
    "scrubbed_strains"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# scrubbed_strains = scrubbed_species_metadata.genome_id.astype('str')\n",
    "\n",
    "df_mash_square = df_mash_square.loc[scrubbed_strains, scrubbed_strains]\n",
    "df_mash_corr = df_mash_corr.loc[scrubbed_strains, scrubbed_strains]\n",
    "df_mash_corr_dist = df_mash_square.loc[scrubbed_strains, scrubbed_strains]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter strains by Mash distance\n",
    "\n",
    "- __Criteria 1:__ Mash value of 0.05 (soft-limit on bacterial species delineation)\n",
    "- __Criteria 2:__ Any clear outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "sns.histplot(df_mash_square.values.flatten())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find your Reference/Representative Strain ID (for filtration)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Auto-detect reference/representative strains from metadata\n_ref_mask = scrubbed_species_metadata['reference_genome'].notna()\n_ref_ids = scrubbed_species_metadata.loc[_ref_mask, 'genome_id'].astype(str)\nrepr_strains = sorted(_ref_ids[_ref_ids.isin(df_mash_square.index)].tolist())\n\nif not repr_strains:\n    # Fallback: use the medoid (genome with smallest mean mash distance)\n    repr_strains = [df_mash_square.mean(axis=1).idxmin()]\n\nprint(f\"Representative strains: {repr_strains}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# This cutoff is dependent on the data you see above\n",
    "# Past studies have gone down as low as 98.5th percentile\n",
    "# but 99th or 99.9th percentiles are also acceptable\n",
    "cutoffs = []\n",
    "\n",
    "for strain in repr_strains:\n",
    "    cutoffs.append(np.quantile(df_mash_square.loc[strain], 0.99))\n",
    "\n",
    "cutoff = sum(cutoffs)/len(cutoffs)\n",
    "cutoff"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for repr_strain in repr_strains:\n",
    "    cond = df_mash_square.loc[repr_strain] < cutoff\n",
    "    good_strains = df_mash_square.loc[repr_strain][cond].index\n",
    "    \n",
    "    df_mash_square = df_mash_square.loc[good_strains, good_strains]\n",
    "    df_mash_corr = df_mash_corr.loc[good_strains, good_strains]\n",
    "    df_mash_corr_dist = df_mash_square.loc[good_strains, good_strains]\n",
    "    \n",
    "df_mash_corr_dist.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "mash_scrubbed_summary = scrubbed_species_metadata.set_index('genome_id').loc[sorted(df_mash_square.index)].reset_index()\n",
    "mash_scrubbed_metadata = scrubbed_species_metadata.set_index('genome_id').loc[sorted(df_mash_square.index)].reset_index()\n",
    "\n",
    "\n",
    "display(\n",
    "    mash_scrubbed_metadata.shape,\n",
    "    mash_scrubbed_metadata.head()\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find threshold for Mash clustering"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cond = scrubbed_species_summary.genome_status == 'Complete'\n",
    "complete_seqs = set(scrubbed_species_summary[cond].genome_id)\n",
    "complete_seqs = sorted(\n",
    "    complete_seqs.intersection(set(df_mash_square.index))\n",
    ")\n",
    "\n",
    "\n",
    "df_mash_square_complete = df_mash_square.loc[complete_seqs, complete_seqs]\n",
    "df_mash_corr_complete = df_mash_square.loc[complete_seqs, complete_seqs]\n",
    "df_mash_corr_dist_complete = df_mash_square.loc[complete_seqs, complete_seqs]\n",
    "\n",
    "df_mash_corr_dist_complete.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Initial sensitivity analysis (gives min val to consider)\n",
    "from pyphylon.mash import sensitivity_analysis, cluster_corr_dist, remove_bad_strains\n",
    "tmp, df_temp, elbow_idx, elbow_threshold = sensitivity_analysis(df_mash_corr_dist_complete)\n",
    "\n",
    "# Plot (tells us to pick something > 0.25)\n",
    "plt.rcParams[\"figure.dpi\"] = 200\n",
    "fig, axs = plt.subplots(figsize=(4,3),)\n",
    "axs.plot(tmp['threshold'], tmp['num_clusters'])\n",
    "plt.axhline(y=df_temp['num_clusters'][elbow_idx], c=\"#ff00ff\", linestyle='--')\n",
    "axs.set_ylabel('num_clusters')\n",
    "axs.set_xlabel('index')\n",
    "fig.suptitle(\n",
    "    f\"Num clusters decelerates \\nafter a value of {df_temp['num_clusters'][elbow_idx]} (threshold: {elbow_threshold})\",\n",
    "    y=1\n",
    ")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot initial clustermap of Mash values"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "elbow_threshold = elbow_threshold+0.1 # \"round\" up\n",
    "\n",
    "link, dist, clst = cluster_corr_dist(df_mash_corr_dist_complete, thresh=elbow_threshold)\n",
    "\n",
    "# Color each cluster\n",
    "cm = matplotlib.colormaps.get_cmap('tab20')\n",
    "clr = dict(zip(sorted(clst.cluster.unique()), cm.colors))\n",
    "clst['color'] = clst.cluster.map(clr)\n",
    "\n",
    "print('Number of colors: ', len(clr))\n",
    "print('Number of clusters', len(clst.cluster.unique()))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "size = 6\n",
    "\n",
    "legend_TN = [patches.Patch(color=c, label=l) for l,c in clr.items()]\n",
    "\n",
    "sns.set(rc={'figure.facecolor':'white'})\n",
    "g = sns.clustermap(\n",
    "    df_mash_square_complete,\n",
    "    figsize=(size,size),\n",
    "    row_linkage=link,\n",
    "    col_linkage=link,\n",
    "    col_colors=clst.color,\n",
    "    yticklabels=False,\n",
    "    xticklabels=False,\n",
    "    cmap='BrBG_r',\n",
    "    robust=True\n",
    ")\n",
    "\n",
    "l2=g.ax_heatmap.legend(loc='upper left', bbox_to_anchor=(1.01,0.85), handles=legend_TN,frameon=True)\n",
    "l2.set_title(title='Clusters',prop={'size':10})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out small clusters (typically with < 5 members)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "small_clst_limit = 0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "px.histogram(pd.DataFrame(clst.cluster.value_counts()), nbins=100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bad_clusters = clst.cluster.value_counts()[clst.cluster.value_counts() < small_clst_limit]\n",
    "bad_clusters"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bad_genomes_list = []\n",
    "\n",
    "for genome in df_mash_square_complete.index:\n",
    "    cluster = clst.loc[genome, 'cluster']\n",
    "    if cluster in bad_clusters:\n",
    "        bad_genomes_list.append(genome)\n",
    "\n",
    "# Update filtration\n",
    "df_mash_square_complete = remove_bad_strains(df_mash_square_complete, bad_genomes_list)\n",
    "df_mash_corr_complete = remove_bad_strains(df_mash_square_complete, bad_genomes_list)\n",
    "df_mash_corr_dist_complete = remove_bad_strains(df_mash_corr_dist_complete, bad_genomes_list)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep filtering until robust clusters show up"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "iteration = 1\n",
    "prev = 0\n",
    "curr = len(clst.cluster.unique())\n",
    "\n",
    "while(np.abs(prev - curr) > 0 ):\n",
    "    print(f'iteration {iteration}...{curr}')\n",
    "    \n",
    "    # Cluster\n",
    "    link, dist, clst = cluster_corr_dist(df_mash_corr_dist_complete, thresh=elbow_threshold)\n",
    "    \n",
    "    # Color each cluster\n",
    "    cm = matplotlib.colormaps.get_cmap('tab20')\n",
    "    clr = dict(zip(sorted(clst.cluster.unique()), cm.colors))\n",
    "    clst['color'] = clst.cluster.map(clr)\n",
    "    \n",
    "    # Increment\n",
    "    prev = curr\n",
    "    curr = len(clst.cluster.unique())\n",
    "    \n",
    "    # Define bad clusters\n",
    "    bad_clusters = clst.cluster.value_counts()[clst.cluster.value_counts() < small_clst_limit]\n",
    "    \n",
    "    # Remove bad genomes\n",
    "    bad_genomes_list = []\n",
    "    for genome in df_mash_square_complete.index:\n",
    "        cluster = clst.loc[genome, 'cluster']\n",
    "        if cluster in bad_clusters:\n",
    "            bad_genomes_list.append(genome)\n",
    "    \n",
    "    # Update filtration\n",
    "    df_mash_square_complete = remove_bad_strains(df_mash_square_complete, bad_genomes_list)\n",
    "    df_mash_corr_complete = remove_bad_strains(df_mash_square_complete, bad_genomes_list)\n",
    "    df_mash_corr_dist_complete = remove_bad_strains(df_mash_corr_dist_complete, bad_genomes_list)\n",
    "    \n",
    "    # Increment\n",
    "    iteration +=1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_mash_square_complete.shape # Current shape after filtration"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "link, dist, clst = cluster_corr_dist(df_mash_corr_dist_complete, thresh=elbow_threshold)\n",
    "\n",
    "# Color each cluster\n",
    "cm = matplotlib.colormaps.get_cmap('tab20')\n",
    "clr = dict(zip(sorted(clst.cluster.unique()), cm.colors))\n",
    "clst['color'] = clst.cluster.map(clr)\n",
    "\n",
    "print('Number of colors: ', len(clr))\n",
    "print('Number of clusters', len(clst.cluster.unique()))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "assert clst.cluster.value_counts().min() >= small_clst_limit"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "px.histogram(clst.cluster.value_counts(), nbins=50)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot filtered Mash clustermap\n",
    "\n",
    "__From this it looks like our final rank for NMF decomposition will be 16 for Enterobacter__"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "size = 6\n",
    "\n",
    "legend_TN = [patches.Patch(color=c, label=l) for l,c in clr.items()]\n",
    "\n",
    "sns.set(rc={'figure.facecolor':'white'})\n",
    "g = sns.clustermap(\n",
    "    df_mash_square_complete,\n",
    "    figsize=(size,size),\n",
    "    row_linkage=link,\n",
    "    col_linkage=link,\n",
    "    col_colors=clst.color,\n",
    "    yticklabels=False,\n",
    "    xticklabels=False,\n",
    "    cmap='BrBG_r',\n",
    "    robust=True\n",
    ")\n",
    "\n",
    "l2=g.ax_heatmap.legend(loc='upper left', bbox_to_anchor=(1.05,0.85), handles=legend_TN,frameon=True)\n",
    "l2.set_title(title='Clusters',prop={'size':10})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Mash-scrubbed `summary` and `metadata`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "mash_scrubbed_metadata = pd.concat([mash_scrubbed_metadata, clst.loc[mash_scrubbed_metadata.genome_id].reset_index().cluster], axis=1)\n",
    "mash_scrubbed_metadata.rename({'cluster':'mash_cluster'}, axis=1, inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "filepath = os.path.join(output_folder, '2b_genome_summary.csv')\nfilepath\nmash_scrubbed_summary.to_csv(filepath)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "filepath = os.path.join(output_folder, '2b_genome_metadata.csv')\nmash_scrubbed_metadata.to_csv(filepath)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Mash results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "filepath = os.path.join(output_folder, '2b_mash_square.csv')\ndf_mash_square.to_csv(filepath)\nfilepath = os.path.join(output_folder, '2b_mash_corr_dist.csv')\ndf_mash_corr_dist.to_csv(filepath)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python pyphylon",
   "language": "python",
   "name": "pyphylontesting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
